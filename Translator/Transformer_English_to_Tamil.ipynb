{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Eelao8bKZju0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def get_device():\n",
        "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def scaled_dot_product(q, k, v, mask=None):\n",
        "    d_k = q.size()[-1]\n",
        "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
        "    if mask is not None:\n",
        "        scaled = scaled.permute(1, 0, 2, 3) + mask\n",
        "        scaled = scaled.permute(1, 0, 2, 3)\n",
        "    attention = F.softmax(scaled, dim=-1)\n",
        "    values = torch.matmul(attention, v)\n",
        "    return values, attention\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_sequence_length):\n",
        "        super().__init__()\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self):\n",
        "        even_i = torch.arange(0, self.d_model, 2).float()\n",
        "        denominator = torch.pow(10000, even_i/self.d_model)\n",
        "        position = (torch.arange(self.max_sequence_length)\n",
        "                          .reshape(self.max_sequence_length, 1))\n",
        "        even_PE = torch.sin(position / denominator)\n",
        "        odd_PE = torch.cos(position / denominator)\n",
        "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
        "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
        "        return PE\n",
        "\n",
        "class SentenceEmbedding(nn.Module):\n",
        "    \"For a given sentence, create an embedding\"\n",
        "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN, UNK_TOKEN='<UNK>'):\n",
        "        super().__init__()\n",
        "        self.vocab_size = len(language_to_index)\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
        "        self.language_to_index = language_to_index\n",
        "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.START_TOKEN = START_TOKEN\n",
        "        self.END_TOKEN = END_TOKEN\n",
        "        self.PADDING_TOKEN = PADDING_TOKEN\n",
        "        self.UNK_TOKEN = UNK_TOKEN\n",
        "        # Ensure UNK_TOKEN is in the vocabulary\n",
        "        if UNK_TOKEN not in language_to_index:\n",
        "            self.language_to_index[UNK_TOKEN] = len(language_to_index)  # Assign a new index\n",
        "\n",
        "    def batch_tokenize(self, batch, start_token, end_token):\n",
        "        def tokenize(sentence, start_token, end_token):\n",
        "            sentence_word_indices = [self.language_to_index.get(token, self.language_to_index[self.UNK_TOKEN]) for token in list(sentence)]\n",
        "            if start_token:\n",
        "                sentence_word_indices.insert(0, self.language_to_index[self.START_TOKEN])\n",
        "            if end_token:\n",
        "                sentence_word_indices.append(self.language_to_index[self.END_TOKEN])\n",
        "\n",
        "            # Truncate the sentence if it exceeds the maximum length\n",
        "            sentence_word_indices = sentence_word_indices[:self.max_sequence_length]\n",
        "\n",
        "            # Pad the sentence if it is shorter than the maximum length\n",
        "            while len(sentence_word_indices) < self.max_sequence_length:\n",
        "                sentence_word_indices.append(self.language_to_index[self.PADDING_TOKEN])\n",
        "\n",
        "            return torch.tensor(sentence_word_indices)\n",
        "\n",
        "        tokenized = []\n",
        "        for sentence_num in range(len(batch)):\n",
        "            tokenized.append(tokenize(batch[sentence_num], start_token, end_token))\n",
        "        return torch.stack(tokenized).to(get_device())\n",
        "\n",
        "    def forward(self, x, start_token, end_token): # sentence\n",
        "        x = self.batch_tokenize(x, start_token, end_token)\n",
        "        x = self.embedding(x)\n",
        "        pos = self.position_encoder().to(get_device())\n",
        "        x = self.dropout(x + pos)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.qkv_layer = nn.Linear(d_model , 3 * d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        qkv = self.qkv_layer(x)\n",
        "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
        "        qkv = qkv.permute(0, 2, 1, 3)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, parameters_shape, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.parameters_shape=parameters_shape\n",
        "        self.eps=eps\n",
        "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
        "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
        "        mean = inputs.mean(dim=dims, keepdim=True)\n",
        "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
        "        std = (var + self.eps).sqrt()\n",
        "        y = (inputs - mean) / std\n",
        "        out = self.gamma * y + self.beta\n",
        "        return out\n",
        "\n",
        "\n",
        "class PositionwiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, self_attention_mask):\n",
        "        residual_x = x.clone()\n",
        "        x = self.attention(x, mask=self_attention_mask)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + residual_x)\n",
        "        residual_x = x.clone()\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + residual_x)\n",
        "        return x\n",
        "\n",
        "class SequentialEncoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, self_attention_mask  = inputs\n",
        "        for module in self._modules.values():\n",
        "            x = module(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialEncoder(*[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob)\n",
        "                                      for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, self_attention_mask, start_token, end_token):\n",
        "        x = self.sentence_embedding(x, start_token, end_token)\n",
        "        x = self.layers(x, self_attention_mask)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MultiHeadCrossAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "        self.kv_layer = nn.Linear(d_model , 2 * d_model)\n",
        "        self.q_layer = nn.Linear(d_model , d_model)\n",
        "        self.linear_layer = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x, y, mask):\n",
        "        batch_size, sequence_length, d_model = x.size()\n",
        "        kv = self.kv_layer(x)\n",
        "        q = self.q_layer(y)\n",
        "        kv = kv.reshape(batch_size, sequence_length, self.num_heads, 2 * self.head_dim)\n",
        "        q = q.reshape(batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        kv = kv.permute(0, 2, 1, 3)\n",
        "        q = q.permute(0, 2, 1, 3)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "        values, attention = scaled_dot_product(q, k, v, mask)\n",
        "        values = values.permute(0, 2, 1, 3).reshape(batch_size, sequence_length, d_model)\n",
        "        out = self.linear_layer(values)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, ffn_hidden, num_heads, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm1 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.encoder_decoder_attention = MultiHeadCrossAttention(d_model=d_model, num_heads=num_heads)\n",
        "        self.layer_norm2 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.layer_norm3 = LayerNormalization(parameters_shape=[d_model])\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask):\n",
        "        _y = y.clone()\n",
        "        y = self.self_attention(y, mask=self_attention_mask)\n",
        "        y = self.dropout1(y)\n",
        "        y = self.layer_norm1(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.encoder_decoder_attention(x, y, mask=cross_attention_mask)\n",
        "        y = self.dropout2(y)\n",
        "        y = self.layer_norm2(y + _y)\n",
        "\n",
        "        _y = y.clone()\n",
        "        y = self.ffn(y)\n",
        "        y = self.dropout3(y)\n",
        "        y = self.layer_norm3(y + _y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class SequentialDecoder(nn.Sequential):\n",
        "    def forward(self, *inputs):\n",
        "        x, y, self_attention_mask, cross_attention_mask = inputs\n",
        "        for module in self._modules.values():\n",
        "            y = module(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 ffn_hidden,\n",
        "                 num_heads,\n",
        "                 drop_prob,\n",
        "                 num_layers,\n",
        "                 max_sequence_length,\n",
        "                 language_to_index,\n",
        "                 START_TOKEN,\n",
        "                 END_TOKEN,\n",
        "                 PADDING_TOKEN):\n",
        "        super().__init__()\n",
        "        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.layers = SequentialDecoder(*[DecoderLayer(d_model, ffn_hidden, num_heads, drop_prob) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token):\n",
        "        y = self.sentence_embedding(y, start_token, end_token)\n",
        "        y = self.layers(x, y, self_attention_mask, cross_attention_mask)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                d_model,\n",
        "                ffn_hidden,\n",
        "                num_heads,\n",
        "                drop_prob,\n",
        "                num_layers,\n",
        "                max_sequence_length,\n",
        "                kn_vocab_size,\n",
        "                english_to_index,\n",
        "                kannada_to_index,\n",
        "                START_TOKEN,\n",
        "                END_TOKEN,\n",
        "                PADDING_TOKEN\n",
        "                ):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, english_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.decoder = Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n",
        "        self.linear = nn.Linear(d_model, kn_vocab_size)\n",
        "        self.device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "    def forward(self,\n",
        "                x,\n",
        "                y,\n",
        "                encoder_self_attention_mask=None,\n",
        "                decoder_self_attention_mask=None,\n",
        "                decoder_cross_attention_mask=None,\n",
        "                enc_start_token=False,\n",
        "                enc_end_token=False,\n",
        "                dec_start_token=True, # We should make this true\n",
        "                dec_end_token=False): # x, y are batch of sentences\n",
        "        x = self.encoder(x, encoder_self_attention_mask, start_token=enc_start_token, end_token=enc_end_token)\n",
        "        out = self.decoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token=dec_start_token, end_token=dec_end_token)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "J6gmFWh-h09p"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    from __main__ import Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O-z6phyrh6MH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sE5WUV-1D8p"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# # Open the file and read the content\n",
        "# with open('norm_english.txt', 'r', encoding='utf-8') as file:\n",
        "#     lines = file.readlines()\n",
        "\n",
        "# # Process the lines\n",
        "# cleaned_lines = []\n",
        "# for line in lines:\n",
        "#     # Strip whitespace\n",
        "#     line = line.strip()\n",
        "#     # Skip empty or irrelevant lines\n",
        "#     if not line or line.isspace():\n",
        "#         continue\n",
        "#     # Optional: Filter for English characters (A-Z, a-z, space, punctuation)\n",
        "#     if any(char.isalpha() or char in [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "#                                       ':', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
        "#            for char in line):\n",
        "#         # Remove unnecessary double quotes within the text\n",
        "#         line = re.sub(r'(?<!\\w)\"|\"(?!\\w)', '', line)\n",
        "#         # Remove extra spaces (e.g., multiple spaces between words)\n",
        "#         line = re.sub(r'\\s+', ' ', line)\n",
        "#         # Remove non-ASCII characters if any\n",
        "#         line = re.sub(r'[^\\x00-\\x7F]+', '', line)\n",
        "#         # Optionally, make the text lowercase if needed\n",
        "#         line = line.lower()\n",
        "#         cleaned_lines.append(line)\n",
        "\n",
        "# # Write the cleaned content to a new file\n",
        "# with open('cleaned_english.txt', 'w', encoding='utf-8') as file:\n",
        "#     file.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "# print(f\"File cleaned successfully. {len(cleaned_lines)} lines retained.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX44EoXMeU-b"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# # Open the file and read the content\n",
        "# with open('norm_tamil.txt', 'r', encoding='utf-8') as file:\n",
        "#     lines = file.readlines()\n",
        "\n",
        "# # Process the lines\n",
        "# cleaned_lines = []\n",
        "# skipped_lines = []\n",
        "\n",
        "# for line in lines:\n",
        "#     # Strip whitespace\n",
        "#     original_line = line.strip()\n",
        "#     if not original_line or original_line.isspace():\n",
        "#         skipped_lines.append(line)\n",
        "#         continue\n",
        "\n",
        "#     # Filter for Tamil characters (Unicode range U+0B80–U+0BFF)\n",
        "#     cleaned_line = re.sub(r'[^\\u0B80-\\u0BFF\\s]', '', original_line)  # Keep only Tamil characters and spaces\n",
        "#     if cleaned_line:\n",
        "#         cleaned_lines.append(cleaned_line)\n",
        "#     else:\n",
        "#         skipped_lines.append(original_line)\n",
        "\n",
        "# # Write the cleaned content to a new file\n",
        "# with open('cleaned_tamil.txt', 'w', encoding='utf-8') as file:\n",
        "#     file.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "# # Display skipped lines\n",
        "# # print(\"Skipped lines:\")\n",
        "# # for line in skipped_lines:\n",
        "# #     print(line.strip())\n",
        "\n",
        "# print(f\"File cleaned successfully. {len(cleaned_lines)} lines retained, {len(skipped_lines)} lines skipped.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQyHaiY4Xg8Q"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# # Open the file and read the content\n",
        "# with open('norm_tamil.txt', 'r', encoding='utf-8') as file:\n",
        "#     lines = file.readlines()\n",
        "\n",
        "# # Process the lines\n",
        "# cleaned_lines = []\n",
        "# skipped_lines = []\n",
        "\n",
        "# for line in lines:\n",
        "#     # Strip whitespace\n",
        "#     original_line = line.strip()\n",
        "#     if not original_line or original_line.isspace():\n",
        "#         skipped_lines.append(line)\n",
        "#         continue\n",
        "\n",
        "#     # Filter for Tamil characters (Unicode range U+0B80–U+0BFF), spaces, and digits\n",
        "#     cleaned_line = re.sub(r'[^\\u0B80-\\u0BFF\\s\\d]', '', original_line)  # Keep Tamil characters, spaces, and numbers\n",
        "#     if cleaned_line:\n",
        "#         cleaned_lines.append(cleaned_line)\n",
        "#     else:\n",
        "#         skipped_lines.append(original_line)\n",
        "\n",
        "# # Write the cleaned content to a new file\n",
        "# with open('cleaned_tamil.txt', 'w', encoding='utf-8') as file:\n",
        "#     file.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "# # # Display skipped lines\n",
        "# # print(\"Skipped lines:\")\n",
        "# # for line in skipped_lines:\n",
        "# #     print(line.strip())\n",
        "\n",
        "# print(f\"File cleaned successfully. {len(cleaned_lines)} lines retained, {len(skipped_lines)} lines skipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7k2djEnaAtM"
      },
      "outputs": [],
      "source": [
        "# import re\n",
        "\n",
        "# # Open the file and read the content\n",
        "# with open('norm_tamil.txt', 'r', encoding='utf-8') as file:\n",
        "#     lines = file.readlines()\n",
        "\n",
        "# # Process the lines\n",
        "# cleaned_lines = []\n",
        "# skipped_lines = []\n",
        "# skipped_indices = []  # List to keep track of the indices of skipped lines\n",
        "\n",
        "# for index, line in enumerate(lines):\n",
        "#     # Strip whitespace\n",
        "#     original_line = line.strip()\n",
        "#     if not original_line or original_line.isspace():\n",
        "#         skipped_lines.append(original_line)\n",
        "#         skipped_indices.append(index)\n",
        "#         continue\n",
        "\n",
        "#     # Filter for Tamil characters (Unicode range U+0B80–U+0BFF), spaces, and digits\n",
        "#     cleaned_line = re.sub(r'[^\\u0B80-\\u0BFF\\s\\d]', '', original_line)\n",
        "#     if cleaned_line:\n",
        "#         cleaned_lines.append(cleaned_line)\n",
        "#     else:\n",
        "#         skipped_lines.append(original_line)\n",
        "#         skipped_indices.append(index)\n",
        "\n",
        "# # Write the cleaned content to a new file\n",
        "# with open('cleaned_tamil.txt', 'w', encoding='utf-8') as file:\n",
        "#     file.write(\"\\n\".join(cleaned_lines))\n",
        "\n",
        "# # Print out skipped lines and their indices\n",
        "# print(\"Skipped lines with indices:\")\n",
        "# for line, index in zip(skipped_lines, skipped_indices):\n",
        "#     print(f\"Index {index}: {line}\")\n",
        "\n",
        "# print(f\"File cleaned successfully. {len(cleaned_lines)} lines retained, {len(skipped_lines)} lines skipped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw8IYU6Ta8As",
        "outputId": "fa7d4500-59de-4588-e6b2-dc85bd1e72af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipped indices and lines:\n",
            "File cleaned successfully. 102979 Tamil lines retained, 102979 English lines retained, 0 lines skipped.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Open both files and try a different encoding if UTF-8 fails\n",
        "try:\n",
        "    with open('norm_tamil.txt', 'r', encoding='utf-8') as tamil_file:\n",
        "        tamil_lines = tamil_file.readlines()\n",
        "except UnicodeDecodeError:\n",
        "    with open('norm_tamil.txt', 'r', encoding='ISO-8859-1') as tamil_file:\n",
        "        tamil_lines = tamil_file.readlines()\n",
        "\n",
        "with open('norm_english.txt', 'r', encoding='utf-8') as english_file:\n",
        "    english_lines = english_file.readlines()\n",
        "\n",
        "# Process the lines\n",
        "cleaned_tamil_lines = []\n",
        "cleaned_english_lines = []\n",
        "skipped_indices = []\n",
        "\n",
        "assert len(tamil_lines) == len(english_lines), \"Files do not have the same number of lines.\"\n",
        "\n",
        "for index, (tamil_line, english_line) in enumerate(zip(tamil_lines, english_lines)):\n",
        "    original_tamil_line = tamil_line.strip()\n",
        "    original_english_line = english_line.strip()\n",
        "    cleaned_tamil_line = re.sub(r'[^\\u0B80-\\u0BFF\\s\\d\\?\\.!,;A-Z]', '', original_tamil_line)\n",
        "    if cleaned_tamil_line:\n",
        "        cleaned_tamil_lines.append(cleaned_tamil_line)\n",
        "        cleaned_english_lines.append(original_english_line)\n",
        "    else:\n",
        "        skipped_indices.append(index)\n",
        "\n",
        "with open('cleaned_tamil.txt', 'w', encoding='utf-8') as tamil_file:\n",
        "    tamil_file.write(\"\\n\".join(cleaned_tamil_lines))\n",
        "with open('cleaned_english.txt', 'w', encoding='utf-8') as english_file:\n",
        "    english_file.write(\"\\n\".join(cleaned_english_lines))\n",
        "\n",
        "print(\"Skipped indices and lines:\")\n",
        "for index in skipped_indices:\n",
        "    print(f\"Index {index}: Tamil -> '{tamil_lines[index].strip()}', English -> '{english_lines[index].strip()}'\")\n",
        "\n",
        "print(f\"File cleaned successfully. {len(cleaned_tamil_lines)} Tamil lines retained, {len(cleaned_english_lines)} English lines retained, {len(skipped_indices)} lines skipped.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bGlaQm51h-CO"
      },
      "outputs": [],
      "source": [
        "english_file = 'cleaned_english.txt'\n",
        "tamil_file = 'cleaned_tamil.txt'\n",
        "\n",
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'\n",
        "UNK_TOKEN = '<UNK>'  # Define the unknown token\n",
        "\n",
        "tamil_vocabulary = [\n",
        "    UNK_TOKEN,  # Include the UNK token\n",
        "    START_TOKEN, ' ', '!', '\\\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    ':', ';', '<', '=', '>', '?', '@',\n",
        "    '[', '\\\\', ']', '^', '_', '`', '’',\n",
        "    'ஃ', 'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ',\n",
        "    'க', 'ங', 'ச', 'ஜ', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஷ', 'ஸ', 'ஹ',\n",
        "    'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்',\n",
        "    '௦', '௧', '௨', '௩', '௪', '௫', '௬', '௭', '௮', '௯',\n",
        "    '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN\n",
        "]\n",
        "\n",
        "english_vocabulary = [\n",
        "    UNK_TOKEN,  # Include the UNK token\n",
        "    START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "    ':', '<', '=', '>', '?', '@', ';',\n",
        "    '[', '\\\\', ']', '^', '_', '`', '’',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "    'y', 'z',\n",
        "    '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QxfF7IX5izY6"
      },
      "outputs": [],
      "source": [
        "index_to_tamil = {k:v for k,v in enumerate(tamil_vocabulary)}\n",
        "tamil_to_index = {v:k for k,v in enumerate(tamil_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gfHI3Nr4izmQ"
      },
      "outputs": [],
      "source": [
        "with open(english_file, 'r', encoding='utf-8') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(tamil_file, 'r', encoding='utf-8') as file:\n",
        "    tamil_sentences = file.readlines()\n",
        "\n",
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 200000\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "tamil_sentences = tamil_sentences[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "tamil_sentences = [sentence.rstrip('\\n') for sentence in tamil_sentences]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "70gT3sL_jgoR",
        "outputId": "dc888d8f-6fd2-4d0b-c175-e4bda543ed80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"very well , thanks . nice to see you again . i haven't seen you for a long time . what have you been doing lately ?\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_sentences[19990]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "e4649G-xjoEA",
        "outputId": "daae6dba-6d04-4f51-f68a-d0ceef39c204"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'மிகவும் நல்லது, நன்றி. உங்களை மீண்டும் சந்திப்பதில் மகிழ்ச்சி. நான் உன்னை நீண்ட நாட்களாக பார்க்கவில்லை. நீங்கள் சமீபத்தில் என்ன செய்து கொண்டிருந்தீர்கள்?'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_sentences[19990]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YckjmeD0jvwk",
        "outputId": "0ebf985c-9fc7-472c-f231-362584e4c7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97th percentile length Tamil: 212.0\n",
            "97th percentile length English: 181.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length Tamil: {np.percentile([len(x) for x in tamil_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heBWRyNQjwtn",
        "outputId": "544a68c4-e380-4ece-953a-c8f735271f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 102979\n",
            "Number of valid sentences: 97827\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1)\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(tamil_sentences)):\n",
        "    tamil_sentence, english_sentence = tamil_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(tamil_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(tamil_sentence, tamil_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(tamil_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uoA1vnhzj30J"
      },
      "outputs": [],
      "source": [
        "tamil_sentences = [tamil_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6umLsQOj8St",
        "outputId": "3bb3d145-abed-4ea5-e07e-40936d864b9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ஏய் மனிதனே, நீங்கள் கொஞ்சம் களை வாங்க விரும்புகிறீர்களா?',\n",
              " 'சில என்ன?',\n",
              " 'களை ! உனக்கு தெரியுமா ? பானை, கஞ்சா, மேரி ஜேன் சில நாள்பட்டது!',\n",
              " 'ஓ , ம்ம் , இல்லை நன்றி .',\n",
              " 'நீங்கள் ஒரு சில வரிகளை செய்ய விரும்பினால் எனக்கும் அடி உள்ளது.']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tamil_sentences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OpPOM2Q6j-E_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 30\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 2\n",
        "max_sequence_length = 200\n",
        "tm_vocab_size = len(tamil_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob, #drop out rate to prevent overfitting\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          tm_vocab_size,\n",
        "                          english_to_index,\n",
        "                          tamil_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3jwCUc3knSo",
        "outputId": "02cb119a-b7ca-404f-f7ab-1fc781e75371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(74, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(105, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=105, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xMNuFMZYktIu"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, english_sentences, tamil_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.tamil_sentences = tamil_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.tamil_sentences[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mlzWSskCkzay"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, tamil_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sYgPshk9ex6C"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YpozhZyulOFG"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=tamil_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jGAy0V4Wla0T"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, tm_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, tm_sentence_length = len(eng_batch[idx]), len(tm_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      tm_chars_to_padding_mask = np.arange(tm_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, tm_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, tm_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, tm_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijvqBnIq0RK1",
        "outputId": "a7028394-4bbc-46d3-ac1e-0590b703dd34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Iteration 0 : 4.056656360626221\n",
            "English: hey man , you wanna buy some weed ?\n",
            "Tamil Translation: ஏய் மனிதனே, நீங்கள் கொஞ்சம் களை வாங்க விரும்புகிறீர்களா?\n",
            "Tamil Prediction: ை ்் ்்்்்்்்  ்்      ்்்்்் ் ்      ்  ்்்்்் ் ் ்்்்்க் ்்்    ்க  ு  ்ு   ு்ு்் ் ்   ்் ் ்் ் ்்   ்்ு   ்்்்்்             ் ்       ் ்க ்கத ்ு ்             ் ்்்  ு்ு்்ு்்்்்் ்்்்்்்் ் ்\n",
            "Evaluation translation (hello how are you?) : ('்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்கக்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்்ு்்்்்்்்்்்்்்்்்்்்்்்்்்க்்்்்்்்்்்்்்்்்கக்்்்ககக்்்்்்்்்ுுுக்்்்்ககுுு்்்்்்்்்்்்்்்்்ு்்்்்்ுு்்்்்்்்்்்்்்்்்்்்்',)\n",
            "-------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[44], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m valid_indicies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m tamil_to_index[PADDING_TOKEN], \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m valid_indicies\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#train_losses.append(loss.item())\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\nithe\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nithe\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\nithe\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, tm_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, tm_batch)\n",
        "        optim.zero_grad()\n",
        "        tm_predictions = transformer(eng_batch,\n",
        "                                     tm_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(tm_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            tm_predictions.view(-1, tm_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == tamil_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"Tamil Translation: {tm_batch[0]}\")\n",
        "            tm_sentence_predicted = torch.argmax(tm_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in tm_sentence_predicted:\n",
        "              if idx == tamil_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_tamil[idx.item()]\n",
        "            print(f\"Tamil Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            tm_sentence = (\"\",)\n",
        "            eng_sentence = (\"hello how are you?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, tm_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          tm_sentence,\n",
        "                                          encoder_self_attention_mask.to(device),\n",
        "                                          decoder_self_attention_mask.to(device),\n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_tamil[next_token_index]\n",
        "                tm_sentence = (tm_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "\n",
        "            print(f\"Evaluation translation (hello how are you?) : {tm_sentence}\")\n",
        "            print(\"-------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Z3FR0rM1hJPp"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  tamil_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, tamil_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              tamil_sentence,\n",
        "                              encoder_self_attention_mask.to(device),\n",
        "                              decoder_self_attention_mask.to(device),\n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_tamil[next_token_index]\n",
        "    tamil_sentence = (tamil_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return tamil_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJi5D0wLqfV9",
        "outputId": "3054cc95-ef63-4975-cf8a-1e13984de553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "என்ன செய்யப் போகிறாய் ?<END>\n"
          ]
        }
      ],
      "source": [
        "translation = translate(\"what are you going to do?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"C:/Users/nithe/Unity/AR_Translator/Translator/Deepspeech/mic_vad_streaming\")\n",
        "\n",
        "from mic_vad_streaming import VADAudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def translate_to_tamil(english_text, transformer_model, _, tamil_index_to_word, config):\n",
        "    english_text = (english_text,)  # format as tuple\n",
        "    tamil_sentence = (\"\",)\n",
        "    for word_counter in range(config[\"max_sequence_length\"]):\n",
        "        enc_mask, dec_self_mask, dec_cross_mask = create_masks(english_text, tamil_sentence)\n",
        "        predictions = transformer_model(\n",
        "            english_text,\n",
        "            tamil_sentence,\n",
        "            enc_mask.to(config[\"device\"]),\n",
        "            dec_self_mask.to(config[\"device\"]),\n",
        "            dec_cross_mask.to(config[\"device\"]),\n",
        "            enc_start_token=False,\n",
        "            enc_end_token=False,\n",
        "            dec_start_token=True,\n",
        "            dec_end_token=False\n",
        "        )\n",
        "        next_token_probs = predictions[0][word_counter]\n",
        "        next_token_index = torch.argmax(next_token_probs).item()\n",
        "        next_token = tamil_index_to_word[next_token_index]\n",
        "        tamil_sentence = (tamil_sentence[0] + next_token,)\n",
        "        if next_token == config[\"END_TOKEN\"]:\n",
        "            break\n",
        "    return tamil_sentence[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def start_deepspeech_translating_from_notebook(model_path, scorer_path, transformer_model,\n",
        "                                               english_to_index, tamil_index_to_word, config,\n",
        "                                               device_index=None, rate=16000):\n",
        "    import deepspeech\n",
        "    import numpy as np\n",
        "    from datetime import datetime\n",
        "    from mic_vad_streaming import VADAudio\n",
        "    import os\n",
        "    import socket\n",
        "    \n",
        "    UDP_IP = \"127.0.0.1\"  # or the IP of the machine running Unity\n",
        "    UDP_PORT = 5065       # port number Unity will listen on\n",
        "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
        "\n",
        "\n",
        "    print('Initializing DeepSpeech model...')\n",
        "    model = deepspeech.Model(model_path)\n",
        "    if scorer_path:\n",
        "        model.enableExternalScorer(scorer_path)\n",
        "\n",
        "    vad_audio = VADAudio(aggressiveness=3, device=device_index, input_rate=rate)\n",
        "    print(\"🎤 Listening... Speak into your mic (Ctrl+C to stop)\")\n",
        "\n",
        "    frames = vad_audio.vad_collector()\n",
        "    stream_context = model.createStream()\n",
        "    wav_data = bytearray()\n",
        "\n",
        "    try:\n",
        "        for frame in frames:\n",
        "            if frame is not None:\n",
        "                stream_context.feedAudioContent(np.frombuffer(frame, np.int16))\n",
        "                wav_data.extend(frame)\n",
        "            else:\n",
        "                english_text = stream_context.finishStream()\n",
        "                if english_text.strip():\n",
        "                    print(f\"\\n🔊 Recognized (EN): {english_text}\")\n",
        "                    tamil_text = translate_to_tamil(\n",
        "                        english_text.strip().lower(),\n",
        "                        transformer_model,\n",
        "                        english_to_index,\n",
        "                        tamil_index_to_word,\n",
        "                        config\n",
        "                    )\n",
        "                    print(f\"🌐 Translated (TA): {tamil_text}\")\n",
        "                    sock.sendto(tamil_text.encode('utf-8'), (UDP_IP, UDP_PORT))\n",
        "                    print(f\"📡 Sent to Unity: '{tamil_text}' → {UDP_IP}:{UDP_PORT}\")\n",
        "\n",
        "\n",
        "                stream_context = model.createStream()\n",
        "                wav_data = bytearray()\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"🛑 Stopped listening\")\n",
        "        vad_audio.destroy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"max_sequence_length\": max_sequence_length,  # this should already be defined in your code\n",
        "    \"END_TOKEN\": END_TOKEN                       # this too should be defined earlier\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# python mic_vad_streaming.py -m C:/Users/nithe/Unity/AR_Translator/Translator/Deepspeech/deepspeech-0.9.3-models.pbmm -s C:/Users/nithe/Unity/AR_Translator/Translator/Deepspeech/deepspeech-0.9.3-models.scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sounddevice as sd\n",
        "print(sd.query_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing DeepSpeech model...\n",
            "🎤 Listening... Speak into your mic (Ctrl+C to stop)\n",
            "\n",
            "🔊 Recognized (EN): how are you doing\n",
            "🌐 Translated (TA): ந்்்     ்   ்்்்்்்்்்்்்்்்<END>\n",
            "📡 Sent to Unity: 'ந்்்     ்   ்்்்்்்்்்்்்்்்<END>' → 127.0.0.1:5065\n",
            "🛑 Stopped listening\n"
          ]
        }
      ],
      "source": [
        "start_deepspeech_translating_from_notebook(\n",
        "    model_path=\"C:/Users/nithe/Unity/AR_Translator/Translator/Deepspeech/deepspeech-0.9.3-models.pbmm\",\n",
        "    scorer_path=\"C:/Users/nithe/Unity/AR_Translator/Translator/Deepspeech/deepspeech-0.9.3-models.scorer\",\n",
        "    transformer_model=transformer,\n",
        "    english_to_index=None,\n",
        "    tamil_index_to_word=index_to_tamil,\n",
        "    config=config,\n",
        "    device_index=3\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
